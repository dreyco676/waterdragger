{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "training_val_df = pd.read_csv('./data/Training_set_values.csv', index_col='id')\n",
    "training_label_df = pd.read_csv('./data/Training_set_labels.csv', index_col='id')\n",
    "training_df = training_val_df.join(training_label_df, how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed column with constant value:  recorded_by\n"
     ]
    }
   ],
   "source": [
    "# data cleaning\n",
    "\n",
    "# remove columns with identical column\n",
    "# region = region_cd\n",
    "rm_cols = ['region']\n",
    "for col in rm_cols:\n",
    "    training_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# remove columns with no uniqueness\n",
    "training_cols = list(training_df.columns.values)\n",
    "for col in training_cols:\n",
    "    unique_elements = len(training_df[col].unique())\n",
    "    if unique_elements == 1:\n",
    "        print('Removed column with constant value: ', col)\n",
    "        training_df.drop(col, axis=1, inplace=True)\n",
    "\n",
    "# deal with null values\n",
    "null_values = [0, 'none' 'None', 'na', 'NA', 'Na', 'Unknown', 'Not Known', '', ' ', 'unknown']\n",
    "for null_val in null_values:\n",
    "    training_df.replace(null_val, np.nan)\n",
    "        \n",
    "# drop columns that are completely NA\n",
    "training_df = training_df.dropna(axis=1, how='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean up free form columns\n",
    "ff_cols = ['funder', 'installer', 'wpt_name', 'scheme_name', 'longitude', 'latitude', 'date_recorded', 'num_private']\n",
    "free_form_df = training_df[ff_cols]\n",
    "for col in ff_cols:\n",
    "    training_df.drop(col, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert remaining non-numeric cols to categorical\n",
    "# pd.to_datetime(training_df['date_recorded'])\n",
    "training_cols = list(training_df.columns.values)\n",
    "for col in training_cols:\n",
    "    if training_df[col].dtype == np.object:\n",
    "        training_df[col] = training_df[col].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['amount_tsh', 'gps_height', 'basin', 'subvillage', 'region_code', 'district_code', 'lga', 'ward', 'population', 'public_meeting', 'scheme_management', 'permit', 'construction_year', 'extraction_type', 'extraction_type_group', 'extraction_type_class', 'management', 'management_group', 'payment', 'payment_type', 'water_quality', 'quality_group', 'quantity', 'quantity_group', 'source', 'source_type', 'source_class', 'waterpoint_type', 'waterpoint_type_group', 'status_group']\namount_tsh                float64\ngps_height                  int64\nbasin                    category\nsubvillage               category\nregion_code              category\ndistrict_code            category\nlga                      category\nward                     category\npopulation                  int64\npublic_meeting           category\nscheme_management        category\npermit                   category\nconstruction_year        category\nextraction_type          category\nextraction_type_group    category\nextraction_type_class    category\nmanagement               category\nmanagement_group         category\npayment                  category\npayment_type             category\nwater_quality            category\nquality_group            category\nquantity                 category\nquantity_group           category\nsource                   category\nsource_type              category\nsource_class             category\nwaterpoint_type          category\nwaterpoint_type_group    category\nstatus_group             category\ndtype: object\n"
     ]
    }
   ],
   "source": [
    "training_cols = list(training_df.columns.values)\n",
    "print(training_cols)\n",
    "training_df['construction_year'] = training_df['construction_year'].astype('category')\n",
    "training_df['district_code'] = training_df['district_code'].astype('category')\n",
    "training_df['region_code'] = training_df['region_code'].astype('category')\n",
    "dummy_col = training_cols.remove('status_group')\n",
    "print(training_df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to numerical vector of 1,0 for all categorical values\n",
    "vect_training_df = pd.get_dummies(training_df, columns=dummy_col, sparse=True)\n",
    "vect_training_df.to_pickle('./data/vect_training.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "vect_df = pd.read_pickle('./data/vect_training.pickle')\n",
    "training_label_df = pd.read_csv('./data/Training_set_labels.csv', index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repl_val = ['functional', 'functional needs repair', 'non functional']\n",
    "y_df = training_label_df[['status_group']]\n",
    "y_df = y_df.replace(repl_val, [0.0, 1.0, 2.0])\n",
    "y = y_df.as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vect_df.as_matrix().astype(np.float)\n",
    "\n",
    "# This is important\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Feature space holds %d observations and %d features\" % X.shape)\n",
    "print(\"Unique target labels:\", np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import KFold\n",
    "\n",
    "\n",
    "def run_cv(X, y, clf_class, **kwargs):\n",
    "    # Construct a kfolds object\n",
    "    kf = KFold(len(y),n_folds=5,shuffle=True)\n",
    "    y_pred = y.copy()\n",
    "\n",
    "    # Iterate through folds\n",
    "    for train_index, test_index in kf:\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train = y[train_index]\n",
    "        # Initialize a classifier with key word arguments\n",
    "        clf = clf_class(**kwargs)\n",
    "        clf.fit(X_train,y_train)\n",
    "        y_pred[test_index] = clf.predict(X_test)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier as RF\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "\n",
    "def accuracy(y_true,y_pred):\n",
    "    # NumPy interprets True and False as 1. and 0.\n",
    "    return np.mean(y_true == y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Support vector machines:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,SVC)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random forest:\")\n",
    "print(\"%.3f\" % accuracy(y, run_cv(X,y,RF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}